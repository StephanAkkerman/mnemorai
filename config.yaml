LOGGING_LEVEL: "DEBUG"

# Anki deck name
DECK_NAME: "mnemorai"

# The model to use for grapheme to phoneme conversion (G2P)
G2P:
  MODEL: "charsiu/g2p_multilingual_byT5_small_100"
  TOKENIZER: "google/byt5-small"
  LANGUAGE_JSON: "data/languages.json"
  IPA_REPO: "StephanAkkerman/english-words-IPA"
  IPA_FILE: "en_US.csv"

# The model to use for generating the mnemonic and creating the verbal cue
LLM:
  # We recommend the models from unsloth: https://docs.unsloth.ai/get-started/all-our-models
  SMALL_MODEL: 
    NAME: "unsloth/gemma-3-4b-it-unsloth-bnb-4bit" 
    VRAM: 3 # 3GB vram
  MEDIUM_MODEL: 
    NAME: "unsloth/Qwen2.5-7B-Instruct-bnb-4bit"
    VRAM: 6 # 6GB vram
  LARGE_MODEL: 
    NAME: "unsloth/gemma-3-12b-it-unsloth-bnb-4bit"
    VRAM: 9 # 9GB vram
  # Options are: None, 4bit, 8bit
  # Use None if you use an unsloth model (these are already quantized)
  QUANTIZATION: None
  USE_LORA: False
  LORA: "StephanAkkerman/Phi-3-mini-4k-instruct-QLoRA-4bit-Mnemonic"
  DELETE_AFTER_USE: False
  OFFLOAD: True
  MNEMONIC_CANDIDATES: 20
  PARAMS:
    max_new_tokens: 512
    #temperature: 0.5

# The model to use for generating the image
IMAGE_GEN:
  SMALL_MODEL: 
    NAME: stabilityai/stable-diffusion-2
    VRAM: 3 # 3GB vram
  MEDIUM_MODEL: 
    NAME: black-forest-labs/FLUX.1-dev
    VRAM: 6 # 6GB vram
  OUTPUT_DIR: "imagine/generated-img"
  FLUX_LORA:
    USE_LORA: False
    LORA_REPO: "ByteDance/Hyper-SD"
    LORA_FILE: "Hyper-FLUX.1-dev-8steps-lora.safetensors"
    LORA_SCALE: 0.125
  OFFLOAD_T5: True # If you have more VRAM, you can set this to False to speed up the process
  DELETE_AFTER_USE: True # Delete the pipeline to clear VRAM after use
  SEQUENTIAL_OFFLOAD: True # Cannot be True if OFFLOAD is True
  OFFLOAD: False # Custom offloading to move everything to CPU after function use
  PARAMS:
    num_inference_steps: 25
    guidance_scale: 3.5
    height: 1024
    width: 1024
    seed: 42